# Instrucciones de Entrenamiento - TP3 Autocodificadores

## Resumen de Cambios

### ‚úÖ C√≥digo Duplicado Eliminado
- Creado m√≥dulo `utilidades_entrenamiento.py` con funciones comunes
- Refactorizados 3 archivos para usar utilidades compartidas
- Reducci√≥n de ~100 l√≠neas de c√≥digo duplicado

### ‚úÖ Arquitecturas Expandidas
- **40 arquitecturas diferentes** organizadas en 6 categor√≠as
- Patrones: Compactas, Amplias, Piramidales, Profundas, Residual-like, H√≠bridas, Experimentales

### ‚úÖ Configuraciones de Entrenamiento
- **√âpocas**: [3000, 5000, 8000]
- **Learning rates**: [0.0001, 0.0005, 0.001, 0.002]
- **Dimensiones latentes**: [2, 3, 4, 5, 6, 8, 10]
- **Total combinaciones posibles**: 3,360 experimentos

---

## Opciones de Entrenamiento

### 1. Entrenamiento Completo (TODAS las configuraciones)

**Script**: `entrenar_todas_configuraciones.py`

```bash
cd /Users/ttoloza/git/personal/unahur/fundamentos-redes-neuronales
python -m tp3.src.entrenar_todas_configuraciones
```

**Caracter√≠sticas**:
- Entrena TODAS las combinaciones (40 arquitecturas √ó 7 dimensiones √ó 3 √©pocas √ó 4 LRs)
- **Total**: 3,360 experimentos
- **Tiempo estimado**: VARIOS D√çAS (depende del hardware)
- Genera reporte completo con an√°lisis estad√≠stico
- Crea visualizaciones comparativas
- Guarda todos los modelos entrenados

**‚ö†Ô∏è ADVERTENCIA**: Esto tomar√° MUCHO tiempo. El script pedir√° confirmaci√≥n antes de comenzar.

---

### 2. Entrenador Grid Search Completo (PARALELO)

**Script**: `entrenador_grid_search_completo.py`

```bash
python -m tp3.src.entrenador_grid_search_completo
```

**Caracter√≠sticas**:
- ‚úÖ **EJECUCI√ìN PARALELA** usando m√∫ltiples CPUs
- ‚úÖ **GRID SEARCH COMPLETO**: Prueba TODAS las combinaciones
- Entrena todas las arquitecturas con todas las dimensiones latentes, √©pocas y learning rates
- **Total**: 3 arquitecturas √ó 5 dimensiones √ó 3 √©pocas √ó 3 LRs = **135 experimentos**
- **Tiempo estimado**: Depende del hardware (con 8 cores ~4-6 horas)
- Genera reporte completo con mejores modelos por dimensi√≥n
- Identifica configuraci√≥n √≥ptima de hiperpar√°metros

**Uso recomendado**: Para encontrar la mejor combinaci√≥n de hiperpar√°metros por arquitectura

---

### 3. B√∫squeda de Arquitecturas √ìptimas (PARALELO)

**Script**: `buscar_arquitecturas_optimas.py`

```bash
python -m tp3.src.buscar_arquitecturas_optimas
```

**Caracter√≠sticas**:
- ‚úÖ **EJECUCI√ìN PARALELA** usando m√∫ltiples CPUs
- Entrena arquitecturas experimentales espec√≠ficas
- Configuraci√≥n optimizada para alta precisi√≥n
- **Total**: ~14 experimentos (configurable en el script)
- **Tiempo estimado**: Mucho m√°s r√°pido con paralelizaci√≥n
- Busca modelos con precisi√≥n > 90%
- Genera reporte de mejores modelos

**Uso recomendado**: Para encontrar la mejor arquitectura r√°pidamente

---

### 4. Comparaci√≥n de Arquitecturas (PARALELO)

**Script**: `comparador_arquitecturas_autocodificador.py`

```bash
python -m tp3.src.comparador_arquitecturas_autocodificador
```

**Caracter√≠sticas**:
- ‚úÖ **EJECUCI√ìN PARALELA** usando m√∫ltiples CPUs
- Entrena todas las arquitecturas con configuraci√≥n actual
- **Total**: Depende de configuraciones en `configuraciones_entrenamiento.py`
- **Tiempo estimado**: M√°s r√°pido que opciones secuenciales
- Usa ProcessPoolExecutor para paralelizaci√≥n
- Genera reporte markdown con resultados

**Uso recomendado**: Para comparar arquitecturas r√°pidamente usando todos los cores

---

## Personalizaci√≥n de Configuraciones

### Modificar Arquitecturas a Entrenar

Edita `tp3/src/configuraciones_arquitecturas.py`:

```python
def obtener_arquitecturas_disponibles():
    return {
        'mi_arquitectura': {
            'codificador': [30, 15, 8],
            'activacion': 'tanh',
            'batch_norm': True,
            'descripcion': 'Mi arquitectura personalizada'
        }
    }
```

### Modificar Par√°metros de Entrenamiento

Edita `tp3/src/configuraciones_entrenamiento.py`:

```python
def obtener_configuracion_entrenamiento():
    return {
        'epocas_lista': [5000],              # √âpocas a probar
        'tasas_aprendizaje': [0.001],        # Learning rates
        'dimensiones_latentes': [2, 5],      # Dimensiones latentes
        'error_objetivo': 0.12,              # Umbral de convergencia
        'paciencia': 300,                    # Early stopping patience
        'tipo_perdida': 'bce',               # 'bce' o 'mse'
        'usar_scheduler': True,              # ReduceLROnPlateau
        'batch_size': 32
    }
```

---

## Entrenar Arquitecturas Espec√≠ficas

### Opci√≥n A: Modificar el script principal

Edita `entrenar_todas_configuraciones.py` o cualquier otro script:

```python
arquitecturas_a_entrenar = [
    'compacta_doble',
    'piramidal_media',
    'amplia_moderada'
]

for arquitectura in arquitecturas_a_entrenar:
    # ... c√≥digo de entrenamiento
```

### Opci√≥n B: Usar la consola interactiva

```bash
python -m tp3.src.consola_interactiva

Permite seleccionar arquitectura, dimensi√≥n latente y par√°metros interactivamente.

---

### Estructura de Salida

### Modelos Guardados

Ubicaci√≥n: `/modelos/`

{{ ... }}
### Reportes Generados

Ubicaci√≥n: `/tp3/resultados/`

Archivos:
- `comparacion_dimensiones_latentes.csv` - **Datos en CSV para an√°lisis**
- `comparacion_dimensiones_latentes.md` - Reporte markdown completo
- `comparacion_dimensiones_latentes.png` - Dashboard con 9 gr√°ficos
- `heatmap_mse.png` - Heatmaps de MSE por arquitectura
- `heatmap_precision.png` - Heatmaps de precisi√≥n por arquitectura
- `analisis_detallado.png` - An√°lisis comparativo detallado
- `entrenamiento_completo_{timestamp}.md` - Reporte completo
- `entrenamiento_completo_{timestamp}.png` - Visualizaciones
- `arquitecturas_experimentales.md` - B√∫squeda de √≥ptimos
- `arquitecturas_experimentales.png` - Resultados experimentales

---

### Para Exploraci√≥n R√°pida (‚ö° PARALELO)
```bash
python -m tp3.src.buscar_arquitecturas_optimas
```
- ~14 experimentos en paralelo
- Usa todos los cores disponibles
- Tiempo reducido significativamente

### Para Grid Search Completo (‚ö° PARALELO)
```bash
python -m tp3.src.entrenador_grid_search_completo
```
- 280 experimentos en paralelo
- Usa todos los cores disponibles
- Tiempo reducido significativamente

### Para Comparaci√≥n de Arquitecturas (‚ö° PARALELO)
```bash
python -m tp3.src.comparador_arquitecturas_autocodificador
```
- Configuraci√≥n personalizable
- Usa todos los cores disponibles
- M√°xima velocidad

### Para B√∫squeda Exhaustiva (D√çAS)
```bash
python -m tp3.src.entrenar_todas_configuraciones
```
- 3,360 experimentos secuenciales
- An√°lisis completo y exhaustivo

---

## Monitoreo del Entrenamiento

Cada script muestra:
- Progreso del experimento actual
- M√©tricas en tiempo real (MSE, precisi√≥n, convergencia)
- Tiempo estimado restante
- Resumen al finalizar

Ejemplo de salida (modo paralelo):
```
============================================================
COMPARACI√ìN DE DIMENSIONES LATENTES (PARALELO)
============================================================

Dimensiones latentes a probar: [2, 3, 4, 5, 6, 8, 10]
Arquitecturas: ['compacta_simple', 'compacta_doble', ...]
Total experimentos: 280
Workers paralelos: 8

üöÄ Iniciando entrenamiento paralelo...

‚úÖ [15/280] L=5, piramidal_media
   MSE: 0.0856, Precisi√≥n: 88.3%, Convergi√≥: S√≠

‚úÖ [16/280] L=3, amplia_moderada
   MSE: 0.1124, Precisi√≥n: 84.1%, Convergi√≥: S√≠

‚úÖ [17/280] L=8, profunda_uniforme
   MSE: 0.0789, Precisi√≥n: 90.2%, Convergi√≥: S√≠
...
```

**Nota**: Los experimentos se completan en orden variable debido a la ejecuci√≥n paralela.

---

## Troubleshooting

### Error: "Out of Memory"
- Reduce `batch_size` en configuraciones
- Entrena menos arquitecturas simult√°neamente
- Usa dimensiones latentes m√°s peque√±as

### Error: "No module named 'tp3'"
```bash
cd /Users/ttoloza/git/personal/unahur/fundamentos-redes-neuronales
python -m tp3.src.{script_name}
```

### Entrenamiento muy lento
- Usa `comparador_arquitecturas_autocodificador.py` (paralelo)
- Reduce n√∫mero de √©pocas en configuraciones
- Entrena solo arquitecturas espec√≠ficas

### Modelos no convergen
- Aumenta `paciencia` en configuraciones
- Reduce `error_objetivo`
- Prueba diferentes `learning_rates`

---

### An√°lisis de Resultados

Despu√©s del entrenamiento, revisa:

1. **CSV**: `comparacion_dimensiones_latentes.csv` - Importa en Excel/Python para an√°lisis personalizado
2. **Reporte markdown**: Tabla completa de resultados con mejores modelos
3. **Gr√°ficos PNG**: 4 archivos con visualizaciones completas
4. **Modelos guardados**: En `/modelos/` para uso posterior

Los mejores modelos se identifican autom√°ticamente en los reportes.

### Generar Gr√°ficos Adicionales

Si ya ejecutaste el entrenamiento y tienes el CSV, puedes generar gr√°ficos adicionales:

```bash
python -m tp3.src.graficar_resultados
```

**Genera**:
- Heatmaps de MSE por arquitectura
- Heatmaps de precisi√≥n por arquitectura
- An√°lisis comparativo detallado
- Top 15 mejores modelos
