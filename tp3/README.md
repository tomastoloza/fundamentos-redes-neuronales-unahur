# Fundamentos de redes neuronales TP3

## Auto codificadores

### Tecnicatura en inteligencia artificial

#### Universidad Nacional de Hurlingham

#### Docente: Emiliano Churruca

### 1. Implementar un auto codificador para las im√°genes binarias de la lista de caracteres del archivo
  Ãßcaracteres.h

Plantear una arquitectura de red para el codificador y decodificador que permitan representar
los datos de entrada que est√°n en dos dimensiones.

Estudien y describan las diferentes arquitecturas y par√°metros que fueron aplicando para
permitir que la red converja adecuadamente.

* Realizar el gr√°fico en dos dimensiones que muestre los datos de entrada en el espacio latente.
* Mostrar c√≥mo la red puede generar un nuevo caracter que no pertenece al conjunto de
  entrenamiento.

### 2. Sobre el mismo conjunto de datos, implementar una variante que funcione como un eliminador de
  ruido.

Plantear una arquitectura de red conveniente para esta tarea.

* Explicar la elecci√≥n. Distorsionen las entradas en diferentes niveles y estudien la capacidad
del auto codificador de eliminar el ruido.

### 3. Plantear y resolver con un auto codificador un escenario donde puedan generar nuevas muestras
  para un problema que ustedes elijan.

El Trabajo deber√° ser presentado por cada grupo el d√≠a 3 de junio. Para su presentaci√≥n usar
powerpoint o cualquier programa similar. En la presentaci√≥n deber√° figurar el t√≠tulo del Trabajo, el
nombre de la materia, el nombre de los integrantes del grupo y la fecha. Para cada √≠tem, primero
comentar lo que se hizo y las decisiones tomadas para llevarlo a cabo (si correspondiera). Luego
exponer las dificultades que se presentaron (si correspondiera) y finalmente exponer los resultados.
Al finalizar la presentaci√≥n deber√°n exponerse las conclusiones del Trabajo.

---

**Respuesta Pregunta 1:**

## Metodolog√≠a: Grid Search Exhaustivo

**¬øQu√© es Grid Search?**
Grid Search (b√∫squeda en grilla) es una t√©cnica de optimizaci√≥n de hiperpar√°metros que eval√∫a sistem√°ticamente todas las combinaciones posibles de un conjunto predefinido de valores para cada hiperpar√°metro. En lugar de probar configuraciones al azar, explora exhaustivamente el espacio de hiperpar√°metros para encontrar la combinaci√≥n √≥ptima.

**Implementaci√≥n en nuestro proyecto:**

Se implement√≥ un grid search completo que eval√∫a **todas las combinaciones** de:
- **6 arquitecturas**: BalancedAE, DeepBalancedAE, DeepReLU_L8, WideTanhAE, BalancedAE_L9, WideReLU_L10
- **6 dimensiones latentes**: [2, 5, 6, 8, 9, 10]
- **2 configuraciones de √©pocas**: [8000, 10000]
- **3 learning rates**: [0.0005, 0.00075, 0.001]

El proceso fue completamente automatizado: cada combinaci√≥n de hiperpar√°metros se entren√≥ de manera sistem√°tica, guardando todos los modelos generados con nombres descriptivos del tipo `tp3_{arquitectura}_lat{dim}_ep{epocas}_lr{lr}`. Durante el entrenamiento, se registraron m√©tricas clave como MSE, precisi√≥n, cantidad real de √©pocas, convergencia y par√°metros utilizados, y todos los resultados se almacenaron en el archivo `grid_search_completo.csv`. Se implement√≥ early stopping con una paciencia de 400 √©pocas para evitar el sobreentrenamiento. Esta estrategia de grid search ofrece ventajas claras: asegura la reproducibilidad de los resultados, garantiza una cobertura completa del espacio de combinaciones sin dejar de lado configuraciones prometedoras, permite realizar an√°lisis estad√≠sticos para identificar patrones de rendimiento y optimiza la selecci√≥n de hiperpar√°metros de manera objetiva, eliminando sesgos en el proceso.

**Arquitecturas m√°s efectivas:**
- **WideTanhAE con dim_latente=8**: 94.73% precisi√≥n, MSE=0.0526 (mejor resultado global)
- **BalancedAE con dim_latente=6**: 93.13% precisi√≥n, MSE=0.0591 (segunda mejor)  
- **WideTanhAE con dim_latente=9**: 92.41% precisi√≥n, MSE=0.0657 (tercer mejor)
- **BalancedAE_L9 con dim_latente=9**: 91.70% precisi√≥n, MSE=0.0693
- **WideTanhAE con dim_latente=5**: 91.43% precisi√≥n, MSE=0.0713

**Descripci√≥n detallada de arquitecturas:**

1. **BalancedAE**: `35 ‚Üí 25 ‚Üí 15 ‚Üí 8 ‚Üí 15 ‚Üí 25 ‚Üí 35`
   - Arquitectura equilibrada con compresi√≥n gradual
   - Activaci√≥n: tanh para evitar "dead ReLU" y mejores l√≠mites de decisi√≥n
   - Latente de 8 dimensiones para mayor capacidad representacional

2. **DeepBalancedAE**: `35 ‚Üí 30 ‚Üí 20 ‚Üí 10 ‚Üí 8 ‚Üí 10 ‚Üí 20 ‚Üí 30 ‚Üí 35`
   - Arquitectura profunda (4 capas por lado) con compresi√≥n m√°s suave
   - Activaci√≥n: tanh para estabilidad y menor riesgo de sobreajuste
   - Dise√±ada para capturar patrones m√°s complejos

3. **DeepReLU_L8**: `35 ‚Üí 30 ‚Üí 20 ‚Üí 10 ‚Üí 8 ‚Üí 10 ‚Üí 20 ‚Üí 30 ‚Üí 35`
   - Misma estructura que DeepBalancedAE pero con activaci√≥n ReLU
   - Prueba si ReLU acelera convergencia sin sacrificar estabilidad
   - Latente medio (8) para balance entre capacidad y compresi√≥n

4. **WideTanhAE**: `35 ‚Üí 25 ‚Üí 18 ‚Üí 12 ‚Üí 18 ‚Üí 25 ‚Üí 35`
   - Arquitectura moderadamente profunda con m√°xima capacidad latente (12)
   - Activaci√≥n: tanh para estabilidad
   - Busca la representaci√≥n m√°s rica posible del espacio latente

5. **BalancedAE_L9**: `35 ‚Üí 25 ‚Üí 15 ‚Üí 9 ‚Üí 15 ‚Üí 25 ‚Üí 35`
   - Variaci√≥n del modelo ganador con latente ligeramente menor (9)
   - Prueba el l√≠mite de compresi√≥n √≥ptimo
   - Mantiene la estructura exitosa de BalancedAE

6. **WideReLU_L10**: `35 ‚Üí 25 ‚Üí 15 ‚Üí 10 ‚Üí 15 ‚Üí 25 ‚Üí 35`
   - Combina la mejor arquitectura (capas 25, 15) con activaci√≥n ReLU
   - Latente de 10 dimensiones (ganador en otros experimentos)
   - Prueba si ReLU acelera convergencia manteniendo buen MSE

**Hallazgos clave:**
1. **Dimensi√≥n latente √≥ptima**: 6-9 dimensiones demuestran el mejor balance. Aunque el m√≠nimo te√≥rico es ‚åàlog2(32)‚åâ=5 bits, dimensiones mayores (6-9) mejoran significativamente la reconstrucci√≥n.
2. **Funci√≥n de activaci√≥n**: **tanh claramente superior a ReLU** - WideTanhAE supera consistentemente a WideReLU_L10 en todas las dimensiones latentes
3. **Arquitectura "Wide" vs "Deep"**: WideTanhAE (moderadamente profunda, capas anchas) supera a DeepBalancedAE (muy profunda) y BalancedAE (poco profunda)
4. **Learning rate √≥ptimo**: 0.001 con √©pocas altas (8000-10000) produce los mejores resultados
5. **Patr√≥n de rendimiento**: WideTanhAE domina en dim_latente 8-9, BalancedAE es competitivo en dim_latente 6
6. **Convergencia**: **Ning√∫n modelo convergi√≥ completamente** (MSE objetivo ‚â§ 0.05), pero el mejor alcanz√≥ MSE=0.0526 (solo 0.0026 por encima)

**Ninguna configuraci√≥n convergi√≥ completamente** (todas marcadas como `convergio=False`) debido al criterio de convergencia estricto: **MSE ‚â§ 0.05**. El mejor modelo alcanz√≥ MSE=0.0526, apenas 0.0026 por encima del objetivo. Esto indica que:
- El criterio es apropiado pero muy exigente para este problema de 32 caracteres
- Los modelos est√°n muy cerca de la convergencia deseada (diferencia < 5%)
- El early stopping con paciencia=400 detuvo el entrenamiento antes de alcanzar el objetivo
- Aumentar √©pocas o ajustar la paciencia podr√≠a lograr convergencia formal, pero las reconstrucciones ya son de alta calidad (94.73% precisi√≥n)

## Generaci√≥n de Nuevos Caracteres

Para responder al requerimiento de **"mostrar c√≥mo la red puede generar un nuevo car√°cter que no pertenece al conjunto de entrenamiento"**, se desarroll√≥ un **Explorador Interactivo** (`explorador_interactivo.py`) que permite:

### üéØ **Funcionalidad Principal**
- **Visualizaci√≥n del espacio latente**: Muestra todos los caracteres entrenados como puntos en el espacio 2D
- **Generaci√≥n interactiva**: Click en cualquier punto del espacio latente para generar un nuevo car√°cter
- **Interpolaci√≥n inteligente**: Distingue entre clicks cerca de caracteres existentes vs. puntos nuevos

### üîß **Mecanismo de Generaci√≥n**
1. **Click cerca de car√°cter existente** (< 0.15 unidades): Usa el vector latente completo del car√°cter
2. **Click en espacio vac√≠o**: Crea un nuevo vector latente con coordenadas del click
3. **Para dimensiones > 2**: Las dimensiones adicionales se inicializan en 0
4. **Decodificaci√≥n**: El vector latente se pasa por el decoder para generar el patr√≥n visual

### üìä **Caracter√≠sticas del Explorador**
- **Visualizaci√≥n en tiempo real**: Muestra el car√°cter generado instant√°neamente
- **Historial de clicks**: Puntos verdes (entrenamiento) vs. naranjas (generados)
- **Informaci√≥n detallada**: Vector latente, estad√≠sticas del patr√≥n, tipo de car√°cter
- **Soporte multidimensional**: Funciona con espacios latentes de cualquier dimensi√≥n

### üí° **Ejemplo de Uso**
```bash
python -m tp3.src.explorador_interactivo --modelo tp3_WideTanhAE_lat8_ep8000_lr0_001
```

**Resultado**: Una interfaz interactiva donde hacer click entre dos caracteres conocidos (ej. entre '0' y '1') genera un car√°cter h√≠brido que combina caracter√≠sticas de ambos, demostrando la capacidad del autocodificador para generar patrones no vistos durante el entrenamiento.

**Visualizaci√≥n de arquitecturas:**

Se generaron diagramas detallados de todas las arquitecturas probadas mostrando:
- Estructura completa encoder-decoder con n√∫mero de neuronas por capa
- Conexiones entre capas y flujo de informaci√≥n
- Capa latente destacada (cuello de botella)
- Funci√≥n de activaci√≥n utilizada (tanh/relu) con c√≥digo de colores
- Cantidad total de par√°metros entrenables
- Descripci√≥n t√©cnica de cada arquitectura

# WideTanh AutoEncoder Latente d=8, 8k Epocas, LR=0.001
![verificacion_tp3_WideTanhAE_lat8_ep8000_lr0_001.png](resultados/verificacion_tp3_WideTanhAE_lat8_ep8000_lr0_001.png)

## Visualizaci√≥n del Espacio Latente

El explorador interactivo (explicado arriba) genera visualizaciones como esta del espacio latente:

```bash
python -m tp3.src.explorador_interactivo --modelo tp3_WideTanhAE_lat8_ep8000_lr0_001
```

![tp3_WideTanhAE_lat8_ep8000_lr0_001_espacio_latente.png](resultados/tp3_WideTanhAE_lat8_ep8000_lr0_001_espacio_latente.png)

**Interpretaci√≥n**: Cada punto representa un car√°cter en el espacio latente 2D. La distribuci√≥n muestra c√≥mo el autocodificador organiza los caracteres seg√∫n sus similitudes visuales. Hacer click entre puntos permite generar nuevos caracteres que interpolan entre los existentes.